{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tcp6PULBCqss"
   },
   "source": [
    "# 5. Capstone Project: Machine Learning Models III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxLOusgfEwks",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "![headerall](./images/headers/header_all.jpg)\n",
    "\n",
    "##  Goals\n",
    "\n",
    "### Project:\n",
    "In this work, we will first analyze where and when traffic congestion is highest and lowest in New York State. We will then build different machine learning models capable of predicting cab travel times in and around New York City using only variables that can be easily obtained from a smartphone app or a website. We will then compare their performance and explore the possibility of using additional variables such as weather forecasts and holidays to improve the predictive performance of the models.\n",
    "\n",
    "### Section:\n",
    "In this section, we will use the knowledge gained during the exploratory data analysis to perform the final feature transformation. Next, we will create and compare the performance of several machine learning models, namely: linear regressions, a support vector machine regressor, a random forest regressor and a gradient boosted decision tree. The feature space and hyperparameters will be optimised for each model to obtain the best possible performance.\n",
    "\n",
    "## Data\n",
    "### External Datasets:\n",
    "- Weather Forecast: The 2018 NYC weather forecast was collected from the [National Weather Service Forecast Office](https://w2.weather.gov/climate/index.php?wfo=okx) website. Daily measurements were taken from January to December 2018 in Central Park. These measures are given in imperial units and include daily minimum and maximum temperatures, precipitations, snowfall, and snow depth.\n",
    "\n",
    "- Holidays: The 2018 NYC holidays list was collected from the [Office Holiday](https://www.officeholidays.com/countries/usa/new-york/2021) website. The dataset contains the name, date, and type of holidays for New York.\n",
    "\n",
    "- Taxi Zones: The NYC Taxi Zones dataset was collected from the [NYC Open Data](https://data.cityofnewyork.us/Transportation/NYC-Taxi-Zones/d3c5-ddgc) website. It contains the pickup and drop-off zones (Location IDs) for the Yellow, Green, and FHV Trip Records. The taxi zones are based on the NYC Department of City Planning’s Neighborhood.\n",
    "\n",
    "### Primary Datasets:\n",
    "\n",
    "- Taxi Trips: The 2018 NYC Taxi Trip dataset was collected from the [Google Big Query](https://console.cloud.google.com/marketplace/product/city-of-new-york/nyc-tlc-trips?project=jovial-monument-300209&folder=&organizationId=) platform. The dataset contains more than 100'000'000 Yellow Taxi Trip records for 2018 and contains an extensive amount of variables including the pick-up and drop-off dates/times, pick-up and drop-off locations, trip distances, itemized fares, rate types, payment types, and driver-reported passenger counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8tvC_V2FEj5"
   },
   "source": [
    "***\n",
    "## Table of Content:\n",
    "    1. Data Preparation\n",
    "        1.1 External Datasets\n",
    "            1.1.1 Weather Forecast Dataset\n",
    "            1.1.2 Holidays Dataset\n",
    "            1.1.3 Taxi Zones Dataset\n",
    "        1.2 Primary Dataset\n",
    "            1.2.1 Taxi Trips Dataset\n",
    "            1.2.2 Taxi Trips Subset\n",
    "    2. Exploratory Data Analysis\n",
    "        2.1 Primary Dataset\n",
    "            2.1.1 Temporal Analysis\n",
    "            2.1.2 Spatio-Temporal Analysis\n",
    "        2.2 External Datasets\n",
    "            2.2.1 Temporal Analysis of Weather Data\n",
    "            2.2.2 Temporal Analysis of Holidays Data\n",
    "        2.3 Combined Dataset\n",
    "            2.3.1 Overall Features Correlation\n",
    "    3. Machine Learning Models\n",
    "        3.1 Data Preparation\n",
    "        3.2 Baselines\n",
    "        3.3 Model Training\n",
    "            3.3.1 Linear Regression\n",
    "            3.3.2 Support Vector Machine\n",
    "            3.3.3 Random Forest\n",
    "            3.3.4 Gradient Boosted Decision Tree\n",
    "        3.4 Final Models Comparison\n",
    "    5. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1WFf7qqEi03",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "***\n",
    "## Python Libraries and Magic Commands Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python core libraries\n",
    "import time\n",
    "\n",
    "# Import data processing libraries gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import Visualization libraries\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import machine learning libraries\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import median_absolute_error as MAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up magic commands\n",
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr: (824654, 33)\n",
      "y_tr: (824654,) float64\n"
     ]
    }
   ],
   "source": [
    "# Import the train dataset\n",
    "train_df = pd.read_pickle(r'data/processed/train.pickle')\n",
    "\n",
    "# Get the independant variables from the train dataset\n",
    "X_tr = train_df.drop(\"trip_duration\", axis=1)\n",
    "\n",
    "# Get the dependant variable from the train dataset\n",
    "y_tr = train_df[\"trip_duration\"]\n",
    "\n",
    "print('X_tr:', X_tr.shape)\n",
    "print('y_tr:', y_tr.shape, y_tr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_te: (206156, 33)\n",
      "y_te: (206156,) float64\n"
     ]
    }
   ],
   "source": [
    "# Import the test dataset\n",
    "test_df = pd.read_pickle(r'data/processed/test.pickle')\n",
    "\n",
    "# Get the independant variables from the test dataset\n",
    "X_te = test_df.drop(\"trip_duration\", axis=1)\n",
    "\n",
    "# Get the dependant variable from the test dataset\n",
    "y_te = test_df[\"trip_duration\"]\n",
    "\n",
    "print('X_te:', X_te.shape)\n",
    "print('y_te:', y_te.shape, y_te.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get id column names from the train dataset\n",
    "id_cols = [c for c in train_df.columns if \"_id\" in c]\n",
    "\n",
    "# Remove ID features in the train dataset\n",
    "X_tr.drop(id_cols, axis=1, inplace=True)\n",
    "\n",
    "# Remove ID features in the test dataset\n",
    "X_te.drop(id_cols, axis=1, inplace=True)\n",
    "\n",
    "# Drop the pickup day of the year variable from the train dataset\n",
    "X_tr.drop(\"pickup_yearday\", axis=1, inplace=True)\n",
    "\n",
    "# Drop the pickup day of the year variable from the test dataset\n",
    "X_te.drop(\"pickup_yearday\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "***\n",
    "## Functions Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that performs preprocessing steps to the selected dataset\n",
    "def preprocess(data, categorical_cols, continuous_cols, transform_cols, polynome_deg=1):\n",
    "\n",
    "    # Create a copy of the data frame\n",
    "    df = data.copy()\n",
    "\n",
    "    # One-hot encode categorical features\n",
    "    df = pd.get_dummies(df, columns=categorical_cols, dummy_na=False)\n",
    "\n",
    "    # Log-transform numerical variables\n",
    "    for col in transform_cols:\n",
    "        df[col] = np.log(df[col])\n",
    "    \n",
    "    # Add polynomial features\n",
    "    for col in continuous_cols:\n",
    "        if polynome_deg > 1:\n",
    "            for poly in range(polynome_deg + 1):\n",
    "                df[\"{}**{}\".format(col, poly)] = df[col] ** poly\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that display individual barplot\n",
    "def plot_barplot(\n",
    "    data,\n",
    "    x_var,\n",
    "    y_var,\n",
    "    xlabel,\n",
    "    ylabel,\n",
    "    title=\"\",\n",
    "    labels=None,\n",
    "    label_order=None,\n",
    "    legend=None,\n",
    "    figsize=(20, 5),\n",
    "    palette=\"YlGnBu\",\n",
    "):\n",
    "    # Create a figure with one column and row\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Generate the plot\n",
    "    if labels == None:\n",
    "        sns.barplot(\n",
    "            x=x_var,\n",
    "            y=y_var,\n",
    "            data=data,\n",
    "            ax=ax,\n",
    "            palette=palette,\n",
    "        )\n",
    "    else:\n",
    "        sns.barplot(\n",
    "            x=x_var,\n",
    "            y=y_var,\n",
    "            hue=labels,\n",
    "            hue_order=label_order,\n",
    "            data=data,\n",
    "            ax=ax,\n",
    "            palette=palette,\n",
    "        )\n",
    "        ax.legend(title=legend)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "    ax.yaxis.set_ticks_position(\"none\")\n",
    "    ax.tick_params(labelsize=14)\n",
    "    ax.set_xlabel(xlabel, fontsize=16)\n",
    "    ax.set_ylabel(ylabel, fontsize=16)\n",
    "    ax.grid()\n",
    "\n",
    "    # Adjust the padding between and around subplots\n",
    "    fig.tight_layout(pad=0.5, w_pad=0.5)\n",
    "\n",
    "    # Add a title to the figure\n",
    "    plt.title(title.title(), fontsize=18, pad=15)\n",
    "    \n",
    "    # Display the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "## 3.3.2 Model Training: Support Vector Machine\n",
    "\n",
    "## Goals:\n",
    "Train and optimise support vector machine regressor models\n",
    "\n",
    "## Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Support Vector Machine: testing different training sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the support vector machine regression model is: 91.2\n",
      "The MAE of the support vector machine regression model model is: 4.7\n",
      "\n",
      "(Exectution time: 2.8 sec)\n"
     ]
    }
   ],
   "source": [
    "# Get time at exectution start\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a pipeline that performs standardization and fit the data to a support vector machine model\n",
    "svr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVR()\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to the preprocessed train dataset\n",
    "svr_model.fit(X_tr[:100], y_tr[:100])\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset with the best hyperparameters \n",
    "svr_y_pred = svr_model.predict(X_te)\n",
    "\n",
    "# Calculate execution time\n",
    "end_time_1 = time.time() - start_time\n",
    "\n",
    "print('The MSE of the support vector machine regression model is: {:.1f}'.format(MSE(y_te, svr_y_pred)))\n",
    "print('The MAE of the support vector machine regression model model is: {:.1f}'.format(MAE(y_te, svr_y_pred)))\n",
    "\n",
    "print('\\n(Exectution time: {:.1f} sec)'.format(end_time_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the support vector machine regression model is: 59.9\n",
      "The MAE of the support vector machine regression model model is: 3.4\n",
      "\n",
      "(Exectution time: 25.9 sec)\n"
     ]
    }
   ],
   "source": [
    "# Get time at exectution start\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a pipeline that performs standardization and fit the data to a support vector machine model\n",
    "svr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVR()\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to the preprocessed train dataset\n",
    "svr_model.fit(X_tr[:1000], y_tr[:1000])\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset with the best hyperparameters \n",
    "svr_y_pred = svr_model.predict(X_te)\n",
    "\n",
    "# Calculate execution time\n",
    "end_time_2 = time.time() - start_time\n",
    "\n",
    "print('The MSE of the support vector machine regression model is: {:.1f}'.format(MSE(y_te, svr_y_pred)))\n",
    "print('The MAE of the support vector machine regression model model is: {:.1f}'.format(MAE(y_te, svr_y_pred)))\n",
    "\n",
    "print('\\n(Exectution time: {:.1f} sec)'.format(end_time_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the support vector machine regression model is: 31.5\n",
      "The MAE of the support vector machine regression model model is: 2.4\n",
      "\n",
      "(Exectution time: 250.8 sec)\n"
     ]
    }
   ],
   "source": [
    "# Get time at exectution start\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a pipeline that performs standardization and fit the data to a support vector machine model\n",
    "svr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVR()\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to the preprocessed train dataset\n",
    "svr_model.fit(X_tr[:10000], y_tr[:10000])\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset with the best hyperparameters \n",
    "svr_y_pred = svr_model.predict(X_te)\n",
    "\n",
    "# Calculate execution time\n",
    "end_time_3 = time.time() - start_time\n",
    "\n",
    "print('The MSE of the support vector machine regression model is: {:.1f}'.format(MSE(y_te, svr_y_pred)))\n",
    "print('The MAE of the support vector machine regression model model is: {:.1f}'.format(MAE(y_te, svr_y_pred)))\n",
    "\n",
    "print('\\n(Exectution time: {:.1f} sec)'.format(end_time_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the support vector machine regression model is: 23.1\n",
      "The MAE of the support vector machine regression model model is: 2.0\n",
      "\n",
      "(Exectution time: 3278.4 sec)\n"
     ]
    }
   ],
   "source": [
    "# Get time at exectution start\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a pipeline that performs standardization and fit the data to a support vector machine model\n",
    "svr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVR()\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to the preprocessed train dataset\n",
    "svr_model.fit(X_tr[:100000], y_tr[:100000])\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset with the best hyperparameters \n",
    "svr_y_pred = svr_model.predict(X_te)\n",
    "\n",
    "# Calculate execution time\n",
    "end_time_4 = time.time() - start_time\n",
    "\n",
    "print('The MSE of the support vector machine regression model is: {:.1f}'.format(MSE(y_te, svr_y_pred)))\n",
    "print('The MAE of the support vector machine regression model model is: {:.1f}'.format(MAE(y_te, svr_y_pred)))\n",
    "\n",
    "print('\\n(Exectution time: {:.1f} sec)'.format(end_time_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:** The training time of a support vector machine regressor increases quadratically with the sample size. Training the model on the full data set would take about 20 hours. Further tests will thus be carried out on a 1% and 10% subset when possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Support Vector Machine: testing different feature spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the support vector machine regression model is: 23.5\n",
      "The MAE of the support vector machine regression model model is: 2.1\n",
      "\n",
      "(Exectution time: 3559.4 sec)\n"
     ]
    }
   ],
   "source": [
    "# Get time at exectution start\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a pipeline that performs standardization and fit the data to a support vector machine model\n",
    "svr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVR()\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to 10 percent of the preprocessed train dataset\n",
    "svr_model.fit(X_tr[:82465], y_tr[:82465])\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset with the best hyperparameters \n",
    "svr_y_pred = svr_model.predict(X_te)\n",
    "\n",
    "# Calculate execution time\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print('The MSE of the support vector machine regression model is: {:.1f}'.format(MSE(y_te, svr_y_pred)))\n",
    "print('The MAE of the support vector machine regression model model is: {:.1f}'.format(MAE(y_te, svr_y_pred)))\n",
    "\n",
    "print('\\n(Exectution time: {:.1f} sec)'.format(end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr: (824654, 26)\n",
      "X_te: (206156, 26)\n"
     ]
    }
   ],
   "source": [
    "# Create a subset of the train matrix without holiday data\n",
    "X_tr_sub1 = X_tr.drop(columns=[col for col in X_tr.columns if \"holiday\" in col])\n",
    "\n",
    "# Create a subset of the test matrix without holiday data\n",
    "X_te_sub1 = X_te.drop(columns=[col for col in X_te.columns if \"holiday\" in col])\n",
    "\n",
    "print(\"X_tr:\", X_tr_sub1.shape)\n",
    "print(\"X_te:\", X_te_sub1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the support vector machine regression model is: 23.3\n",
      "The MAE of the support vector machine regression model model is: 2.1\n",
      "\n",
      "(Exectution time: 3496.2 sec)\n"
     ]
    }
   ],
   "source": [
    "# Get time at exectution start\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a pipeline that performs standardization and fit the data to a support vector machine model\n",
    "svr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVR()\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to 10 percent of the preprocessed train dataset\n",
    "svr_model.fit(X_tr_sub1[:82465], y_tr[:82465])\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset with the best hyperparameters \n",
    "svr_y_pred = svr_model.predict(X_te_sub1)\n",
    "\n",
    "# Calculate execution time\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print('The MSE of the support vector machine regression model is: {:.1f}'.format(MSE(y_te, svr_y_pred)))\n",
    "print('The MAE of the support vector machine regression model model is: {:.1f}'.format(MAE(y_te, svr_y_pred)))\n",
    "\n",
    "print('\\n(Exectution time: {:.1f} sec)'.format(end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr: (824654, 20)\n",
      "X_te: (206156, 20)\n"
     ]
    }
   ],
   "source": [
    "# Create a subset of the train matrix without weather forecast data\n",
    "X_tr_sub2 = X_tr.drop(columns=[col for col in X_tr.columns if \"wf\" in col])\n",
    "\n",
    "# Create a subset of the test matrix without weather forecast data\n",
    "X_te_sub2 = X_te.drop(columns=[col for col in X_te.columns if \"wf\" in col])\n",
    "\n",
    "print(\"X_tr:\", X_tr_sub2.shape)\n",
    "print(\"X_te:\", X_te_sub2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the support vector machine regression model is: 22.1\n",
      "The MAE of the support vector machine regression model model is: 2.0\n",
      "\n",
      "(Exectution time: 3125.3 sec)\n"
     ]
    }
   ],
   "source": [
    "# Get time at exectution start\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a pipeline that performs standardization and fit the data to a support vector machine model\n",
    "svr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVR()\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to 10 percent of the preprocessed train dataset\n",
    "svr_model.fit(X_tr_sub2[:82465], y_tr[:82465])\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset with the best hyperparameters \n",
    "svr_y_pred = svr_model.predict(X_te_sub2)\n",
    "\n",
    "# Calculate execution time\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print('The MSE of the support vector machine regression model is: {:.1f}'.format(MSE(y_te, svr_y_pred)))\n",
    "print('The MAE of the support vector machine regression model model is: {:.1f}'.format(MAE(y_te, svr_y_pred)))\n",
    "\n",
    "print('\\n(Exectution time: {:.1f} sec)'.format(end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr: (824654, 18)\n",
      "X_te: (206156, 18)\n"
     ]
    }
   ],
   "source": [
    "# Create a subset of the train matrix without holiday and weather forecastdata\n",
    "X_tr_sub3 = X_tr.drop(columns=[col for col in X_tr.columns if \"wf\" in col or \"holiday\" in col])\n",
    "                               \n",
    "# Create a subset of the test matrix without holiday and weather forecast data\n",
    "X_te_sub3 = X_te.drop(columns=[col for col in X_te.columns if \"wf\" in col or \"holiday\" in col])\n",
    "\n",
    "print(\"X_tr:\", X_tr_sub3.shape)\n",
    "print(\"X_te:\", X_te_sub3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the support vector machine regression model is: 21.8\n",
      "The MAE of the support vector machine regression model model is: 2.0\n",
      "\n",
      "(Exectution time: 3065.4 sec)\n"
     ]
    }
   ],
   "source": [
    "# Get time at exectution start\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a pipeline that performs standardization and fit the data to a support vector machine model\n",
    "svr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVR()\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to 10 percent of the preprocessed train dataset\n",
    "svr_model.fit(X_tr_sub3[:82465], y_tr[:82465])\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset with the best hyperparameters \n",
    "svr_y_pred = svr_model.predict(X_te_sub3)\n",
    "\n",
    "# Calculate execution time\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print('The MSE of the support vector machine regression model is: {:.1f}'.format(MSE(y_te, svr_y_pred)))\n",
    "print('The MAE of the support vector machine regression model model is: {:.1f}'.format(MAE(y_te, svr_y_pred)))\n",
    "\n",
    "print('\\n(Exectution time: {:.1f} sec)'.format(end_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:** Reducing the feature space by removing less informative variables does not affect performance, but significantly reduces computation time. It can also results in a more accurate and interpretable model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Support Vector Machine: testing dimensionality reduction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the support vector machine regression model is: 24.8\n",
      "The MAE of the support vector machine regression model model is: 2.1\n",
      "\n",
      "(Exectution time: 3089.6 sec)\n"
     ]
    }
   ],
   "source": [
    "# Get time at exectution start\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a pipeline that performs standardization and fit the data to a support vector machine model\n",
    "svr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PCA(n_components=0.95),\n",
    "    SVR()\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to 10 percent of the preprocessed train dataset\n",
    "svr_model.fit(X_tr[:82465], y_tr[:82465])\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset with the best hyperparameters \n",
    "svr_y_pred = svr_model.predict(X_te)\n",
    "\n",
    "# Calculate execution time\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print('The MSE of the support vector machine regression model is: {:.1f}'.format(MSE(y_te, svr_y_pred)))\n",
    "print('The MAE of the support vector machine regression model model is: {:.1f}'.format(MAE(y_te, svr_y_pred)))\n",
    "\n",
    "print('\\n(Exectution time: {:.1f} sec)'.format(end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the support vector machine regression model is: 23.6\n",
      "The MAE of the support vector machine regression model model is: 2.1\n",
      "\n",
      "(Exectution time: 3364.0 sec)\n"
     ]
    }
   ],
   "source": [
    "# Get time at exectution start\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a pipeline that performs standardization and fit the data to a support vector machine model\n",
    "svr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PCA(n_components=0.99),\n",
    "    SVR()\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to 10 percent of the preprocessed train dataset\n",
    "svr_model.fit(X_tr[:82465], y_tr[:82465])\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset with the best hyperparameters \n",
    "svr_y_pred = svr_model.predict(X_te)\n",
    "\n",
    "# Calculate execution time\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print('The MSE of the support vector machine regression model is: {:.1f}'.format(MSE(y_te, svr_y_pred)))\n",
    "print('The MAE of the support vector machine regression model model is: {:.1f}'.format(MAE(y_te, svr_y_pred)))\n",
    "\n",
    "print('\\n(Exectution time: {:.1f} sec)'.format(end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the support vector machine regression model is: 22.7\n",
      "The MAE of the support vector machine regression model model is: 2.0\n",
      "\n",
      "(Exectution time: 2814.5 sec)\n"
     ]
    }
   ],
   "source": [
    "# Get time at exectution start\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a pipeline that performs standardization and fit the data to a support vector machine model\n",
    "svr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PCA(n_components=0.95),\n",
    "    SVR()\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to 10 percent of the preprocessed train dataset\n",
    "svr_model.fit(X_tr_sub3[:82465], y_tr[:82465])\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset with the best hyperparameters \n",
    "svr_y_pred = svr_model.predict(X_te_sub3)\n",
    "\n",
    "# Calculate execution time\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print('The MSE of the support vector machine regression model is: {:.1f}'.format(MSE(y_te, svr_y_pred)))\n",
    "print('The MAE of the support vector machine regression model model is: {:.1f}'.format(MAE(y_te, svr_y_pred)))\n",
    "\n",
    "print('\\n(Exectution time: {:.1f} sec)'.format(end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the support vector machine regression model is: 21.9\n",
      "The MAE of the support vector machine regression model model is: 2.0\n",
      "\n",
      "(Exectution time: 3032.7 sec)\n"
     ]
    }
   ],
   "source": [
    "# Get time at exectution start\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a pipeline that performs standardization and fit the data to a support vector machine model\n",
    "svr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PCA(n_components=0.99),\n",
    "    SVR()\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to 10 percent of the preprocessed train dataset\n",
    "svr_model.fit(X_tr_sub3[:82465], y_tr[:82465])\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset with the best hyperparameters \n",
    "svr_y_pred = svr_model.predict(X_te_sub3)\n",
    "\n",
    "# Calculate execution time\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print('The MSE of the support vector machine regression model is: {:.1f}'.format(MSE(y_te, svr_y_pred)))\n",
    "print('The MAE of the support vector machine regression model model is: {:.1f}'.format(MAE(y_te, svr_y_pred)))\n",
    "\n",
    "print('\\n(Exectution time: {:.1f} sec)'.format(end_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:** Reducing the feature space with principal component analysis (PCA) worsens the performance of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Support Vector Machine: testing different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 49 candidates, totalling 147 fits\n",
      "The MSE of the support vector machine regression model is: 23.9\n",
      "The MAE of the support vector machine regression model model is: 2.1\n",
      "\n",
      " The best parameters across all searched params: \n",
      " {'svr__C': 1000.0, 'svr__gamma': 0.01}\n",
      "\n",
      "(Exectution time: 1068.9 sec)\n"
     ]
    }
   ],
   "source": [
    "# Get time at exectution start\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a pipeline that performs standardization and fit the data to a support vector machine model\n",
    "svr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVR()\n",
    ")\n",
    "\n",
    "# Define a set of hyperparameters to be tested during gridsearch\n",
    "svr_model_params = {\n",
    "    'svr__C':  np.logspace(-3, 3, num=7),\n",
    "    'svr__gamma':  np.logspace(-3, 3, num=7)\n",
    "}\n",
    "\n",
    "# Create a gridsearch object to find the optimum hyperparameters\n",
    "svr_model_gs = GridSearchCV(\n",
    "    svr_model,\n",
    "    svr_model_params,\n",
    "    cv=3,\n",
    "    return_train_score=True,\n",
    "    verbose=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to 1 percent of the preprocessed train dataset\n",
    "svr_model_gs.fit(X_tr_sub3[:8247], y_tr[:8247])\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset with the best hyperparameters \n",
    "svr_y_pred = svr_model_gs.predict(X_te_sub3)\n",
    "\n",
    "# Calculate execution time\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print('The MSE of the support vector machine regression model is: {:.1f}'.format(MSE(y_te, svr_y_pred)))\n",
    "print('The MAE of the support vector machine regression model model is: {:.1f}'.format(MAE(y_te, svr_y_pred)))\n",
    "\n",
    "print(\"\\n The best parameters across all searched params: \\n\", svr_model_gs.best_params_)\n",
    "print('\\n(Exectution time: {:.1f} sec)'.format(end_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine: final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the support vector machine regression model is: 19.9\n",
      "The MAE of the support vector machine regression model model is: 1.9\n",
      "\n",
      "(Exectution time: 12282.7 sec)\n"
     ]
    }
   ],
   "source": [
    "# Get time at exectution start\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a pipeline that performs standardization and fit the data to a support vector machine model\n",
    "svr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVR(\n",
    "        C=1000,\n",
    "        gamma=0.01\n",
    "    )\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to 10 percent of the train dataset\n",
    "svr_model.fit(X_tr_sub3[:82465], y_tr[:82465])\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset with the best hyperparameters \n",
    "svr_y_pred = svr_model.predict(X_te_sub3)\n",
    "\n",
    "# Calculate execution time\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print('The MSE of the support vector machine regression model is: {:.1f}'.format(MSE(y_te, svr_y_pred)))\n",
    "print('The MAE of the support vector machine regression model model is: {:.1f}'.format(MAE(y_te, svr_y_pred)))\n",
    "\n",
    "print('\\n(Exectution time: {:.1f} sec)'.format(end_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Export Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data frame containing the MSE and MAE of the model\n",
    "svr_results = pd.DataFrame({\n",
    "    'model':['svr'],\n",
    "    'mse':[MSE(y_te, svr_y_pred)],\n",
    "    'mae':[MAE(y_te, svr_y_pred)],\n",
    "})\n",
    "\n",
    "# Save the results in the project folder\n",
    "svr_results.to_csv('results/svr_model.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPBFy6LDJ28+i+mv+3BWFx7",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "01.data",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "f0bf25c6fa4e57b7fa36a98c8f4215014c209bd59bf7f61e8cb59f3c04a18758"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "f0bf25c6fa4e57b7fa36a98c8f4215014c209bd59bf7f61e8cb59f3c04a18758"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
