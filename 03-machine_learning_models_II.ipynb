{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tcp6PULBCqss"
   },
   "source": [
    "# 5. Capstone Project: Machine Learning Models II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxLOusgfEwks"
   },
   "source": [
    "***\n",
    "\n",
    "![headerall](./images/headers/header_all.jpg)\n",
    "\n",
    "##  Goals\n",
    "\n",
    "### Project:\n",
    "In this work, we will first analyze where and when traffic congestion is highest and lowest in New York State. We will then build different machine learning models capable of predicting cab travel times in and around New York City using only variables that can be easily obtained from a smartphone app or a website. We will then compare their performance and explore the possibility of using additional variables such as weather forecasts and holidays to improve the predictive performance of the models.\n",
    "\n",
    "### Section:\n",
    "In this section, we will use the knowledge gained during the exploratory data analysis to perform the final feature transformation. Next, we will create and compare the performance of several machine learning models, namely: linear regressions, a support vector machine regressor, a random forest regressor and a gradient boosted decision tree. The feature space and hyperparameters will be optimised for each model to obtain the best possible performance.\n",
    "\n",
    "## Data\n",
    "### External Datasets:\n",
    "- Weather Forecast: The 2018 NYC weather forecast was collected from the [National Weather Service Forecast Office](https://w2.weather.gov/climate/index.php?wfo=okx) website. Daily measurements were taken from January to December 2018 in Central Park. These measures are given in imperial units and include daily minimum and maximum temperatures, precipitations, snowfall, and snow depth.\n",
    "\n",
    "- Holidays: The 2018 NYC holidays list was collected from the [Office Holiday](https://www.officeholidays.com/countries/usa/new-york/2021) website. The dataset contains the name, date, and type of holidays for New York.\n",
    "\n",
    "- Taxi Zones: The NYC Taxi Zones dataset was collected from the [NYC Open Data](https://data.cityofnewyork.us/Transportation/NYC-Taxi-Zones/d3c5-ddgc) website. It contains the pickup and drop-off zones (Location IDs) for the Yellow, Green, and FHV Trip Records. The taxi zones are based on the NYC Department of City Planning’s Neighborhood.\n",
    "\n",
    "### Primary Datasets:\n",
    "\n",
    "- Taxi Trips: The 2018 NYC Taxi Trip dataset was collected from the [Google Big Query](https://console.cloud.google.com/marketplace/product/city-of-new-york/nyc-tlc-trips?project=jovial-monument-300209&folder=&organizationId=) platform. The dataset contains more than 100'000'000 Yellow Taxi Trip records for 2018 and contains an extensive amount of variables including the pick-up and drop-off dates/times, pick-up and drop-off locations, trip distances, itemized fares, rate types, payment types, and driver-reported passenger counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8tvC_V2FEj5"
   },
   "source": [
    "***\n",
    "## Table of Content:\n",
    "    1. Data Preparation\n",
    "        1.1 External Datasets\n",
    "            1.1.1 Weather Forecast Dataset\n",
    "            1.1.2 Holidays Dataset\n",
    "            1.1.3 Taxi Zones Dataset\n",
    "        1.2 Primary Dataset\n",
    "            1.2.1 Taxi Trips Dataset\n",
    "            1.2.2 Taxi Trips Subset\n",
    "    2. Exploratory Data Analysis\n",
    "        2.1 Primary Dataset\n",
    "            2.1.1 Temporal Analysis\n",
    "            2.1.2 Spatio-Temporal Analysis\n",
    "        2.2 External Datasets\n",
    "            2.2.1 Temporal Analysis of Weather Data\n",
    "            2.2.2 Temporal Analysis of Holidays Data\n",
    "        2.3 Combined Dataset\n",
    "            2.3.1 Overall Features Correlation\n",
    "    3. Machine Learning Models\n",
    "        3.1 Data Preparation\n",
    "        3.2 Baselines\n",
    "        3.3 Model Training\n",
    "            3.3.1 Linear Regression\n",
    "            3.3.2 Support Vector Machine\n",
    "            3.3.3 Random Forest\n",
    "            3.3.4 Gradient Boosted Decision Tree\n",
    "        3.4 Final Models Comparison\n",
    "    4. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1WFf7qqEi03",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "***\n",
    "## Python Libraries and Magic Commands Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data processing libraris gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import Visualization librairies\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import machine learning libraries\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import median_absolute_error as MAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up magic commands\n",
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr: (824654, 33)\n",
      "y_tr: (824654,) float64\n"
     ]
    }
   ],
   "source": [
    "# Import the train dataset\n",
    "train_df = pd.read_pickle(r'data/processed/train.pickle')\n",
    "\n",
    "# Get the independant variables from the train dataset\n",
    "X_tr = train_df.drop(\"trip_duration\", axis=1)\n",
    "\n",
    "# Get the dependant variable from the train dataset\n",
    "y_tr = train_df[\"trip_duration\"]\n",
    "\n",
    "print('X_tr:', X_tr.shape)\n",
    "print('y_tr:', y_tr.shape, y_tr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_te: (206156, 33)\n",
      "y_te: (206156,) float64\n"
     ]
    }
   ],
   "source": [
    "# Import the test dataset\n",
    "test_df = pd.read_pickle(r'data/processed/test.pickle')\n",
    "\n",
    "# Get the independant variables from the test dataset\n",
    "X_te = test_df.drop(\"trip_duration\", axis=1)\n",
    "\n",
    "# Get the dependant variable from the test dataset\n",
    "y_te = test_df[\"trip_duration\"]\n",
    "\n",
    "print('X_te:', X_te.shape)\n",
    "print('y_te:', y_te.shape, y_te.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get id column names from the train dataset\n",
    "id_cols = [c for c in train_df.columns if \"_id\" in c]\n",
    "\n",
    "# Remove ID features in the train dataset\n",
    "X_tr.drop(id_cols, axis=1, inplace=True)\n",
    "\n",
    "# Remove ID features in the test dataset\n",
    "X_te.drop(id_cols, axis=1, inplace=True)\n",
    "\n",
    "# Drop the pickup day of the year variable from the train dataset\n",
    "X_tr.drop(\"pickup_yearday\", axis=1, inplace=True)\n",
    "\n",
    "# Drop the pickup day of the year variable from the test dataset\n",
    "X_te.drop(\"pickup_yearday\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "***\n",
    "## Functions Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that performs preprocessing steps to the selected dataset\n",
    "def preprocess(data, categorical_cols, continuous_cols, transform_cols, polynome_deg=1):\n",
    "\n",
    "    # Create a copy of the data frame\n",
    "    df = data.copy()\n",
    "\n",
    "    # One-hot encode categorical features\n",
    "    df = pd.get_dummies(df, columns=categorical_cols, dummy_na=False)\n",
    "\n",
    "    # Log-transform numerical variables\n",
    "    for col in transform_cols:\n",
    "        df[col] = np.log(df[col])\n",
    "    \n",
    "    # Add polynomial features\n",
    "    for col in continuous_cols:\n",
    "        if polynome_deg > 1:\n",
    "            for poly in range(polynome_deg + 1):\n",
    "                df[\"{}**{}\".format(col, poly)] = df[col] ** poly\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "***\n",
    "## Variable Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of categorical variables\n",
    "categorical_cols = [\n",
    "    \"pickup_month\",\n",
    "    \"pickup_week\",\n",
    "    \"pickup_weekday\",\n",
    "    \"pickup_weekday_type\",\n",
    "    \"pickup_hour\",\n",
    "    \"pickup_hour_type\",\n",
    "    \"wf_avg_temp_lvl\",\n",
    "    \"wf_prec_lvl\",\n",
    "    \"wf_new_snow_lvl\",\n",
    "    \"wf_snow_depth_lvl\",\n",
    "    \"holiday_type\",\n",
    "    \"holiday\",\n",
    "    \"trip_within_borough\",\n",
    "    \"tolls_amount_lvl\",\n",
    "]\n",
    "\n",
    "# Define a list of continuous variables\n",
    "continuous_cols = [\n",
    "    \"trip_distance\",\n",
    "    \"tolls_amount\",\n",
    "    \"wf_avg_temp\",\n",
    "    \"wf_prec\",\n",
    "    \"wf_new_snow\",\n",
    "    \"wf_snow_depth\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "## 3.3 Machine Learning Models: Model Training\n",
    "## 3.3.1 Model Training: Linear Regression\n",
    "\n",
    "## Goals:\n",
    "Train and optimise linear regression models\n",
    "\n",
    "## Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression: testing preprocessing performance impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the linear regression model is: 114.9\n",
      "The MAE of the linear regression model is: 3.1\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that performs standardization and fit the data to linear regression model\n",
    "lr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=LinearRegression(), func=np.log, inverse_func=np.exp\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to the train dataset\n",
    "lr_model.fit(X_tr, y_tr)\n",
    "\n",
    "# Predict the target variable of the test dataset\n",
    "lr_y_pred = lr_model.predict(X_te)\n",
    "\n",
    "print('The MSE of the linear regression model is: {:.1f}'.format(MSE(y_te, lr_y_pred)))\n",
    "print('The MAE of the linear regression model is: {:.1f}'.format(MAE(y_te, lr_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr: (824654, 139)\n",
      "X_te: (206156, 139)\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to the train dataset\n",
    "X_tr_p = preprocess(X_tr, categorical_cols, continuous_cols, [\"trip_distance\"])\n",
    "\n",
    "# Apply preprocessing to the train dataset\n",
    "X_te_p = preprocess(X_te, categorical_cols, continuous_cols, [\"trip_distance\"])\n",
    "\n",
    "print(\"X_tr:\", X_tr_p.shape)\n",
    "print(\"X_te:\", X_te_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the linear regression model is: 26.1\n",
      "The MAE of the linear regression model is: 2.1\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that performs standardization and fit the data to linear regression model\n",
    "lr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=LinearRegression(), func=np.log, inverse_func=np.exp\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to the preprocessed train dataset\n",
    "lr_model.fit(X_tr_p, y_tr)\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset\n",
    "lr_y_pred = lr_model.predict(X_te_p)\n",
    "\n",
    "print('The MSE of the linear regression model is: {:.1f}'.format(MSE(y_te, lr_y_pred)))\n",
    "print('The MAE of the linear regression model is: {:.1f}'.format(MAE(y_te, lr_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:** The log-transformation of continuous variables and the one-hot-encoding of categorical features significantly improve the performance of our linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Linear Regression: testing different linear models and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr: (824654, 139)\n",
      "X_te: (206156, 139)\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to the train dataset\n",
    "X_tr_p0 = preprocess(X_tr, categorical_cols, continuous_cols, [\"trip_distance\"])\n",
    "\n",
    "# Apply preprocessing to the train dataset\n",
    "X_te_p0 = preprocess(X_te, categorical_cols, continuous_cols, [\"trip_distance\"])\n",
    "\n",
    "print(\"X_tr:\", X_tr_p.shape)\n",
    "print(\"X_te:\", X_te_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the linear regression model is: 26.1\n",
      "The MAE of the linear regression model is: 2.1\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that performs standardization and fit the data to linear regression model\n",
    "lr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=LinearRegression(), func=np.log, inverse_func=np.exp\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to the preprocessedtrain dataset\n",
    "lr_model.fit(X_tr_p0, y_tr)\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset\n",
    "lr_y_pred = lr_model.predict(X_te_p0)\n",
    "\n",
    "print('The MSE of the linear regression model is: {:.1f}'.format(MSE(y_te, lr_y_pred)))\n",
    "print('The MAE of the linear regression model is: {:.1f}'.format(MAE(y_te, lr_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "The MSE of the linear regression model is: 25.9\n",
      "The MAE of the linear regression model is: 2.1\n",
      "\n",
      " The best parameters across all searched params:\n",
      " {'transformedtargetregressor__regressor__alpha': 10000.0}\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that performs standardization and fit the data to Ridge regression model\n",
    "rr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    TransformedTargetRegressor(regressor=Ridge(), func=np.log, inverse_func=np.exp),\n",
    ")\n",
    "\n",
    "# Define a set of hyperparameters to be tested during gridsearch\n",
    "rr_model_params = {\n",
    "    \"transformedtargetregressor__regressor__alpha\": np.logspace(-1, 4, num=10)\n",
    "}\n",
    "\n",
    "# Create a gridsearch object to find the optimum hyperparameters\n",
    "rr_model_gs = GridSearchCV(\n",
    "    rr_model,\n",
    "    rr_model_params,\n",
    "    cv=5,\n",
    "    return_train_score=True,\n",
    "    verbose=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to the preprocessed train dataset\n",
    "rr_model_gs.fit(X_tr_p0, y_tr)\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset with the best hyperparameters \n",
    "rr_y_pred = rr_model_gs.predict(X_te_p0)\n",
    "\n",
    "print('The MSE of the linear regression model is: {:.1f}'.format(MSE(y_te, rr_y_pred)))\n",
    "print('The MAE of the linear regression model is: {:.1f}'.format(MAE(y_te, rr_y_pred)))\n",
    "\n",
    "print(\"\\n The best parameters across all searched params:\\n\",rr_model_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "The MSE of the linear regression model is: 26.5\n",
      "The MAE of the linear regression model is: 2.1\n",
      "\n",
      " The best parameters across all searched params:\n",
      " {'transformedtargetregressor__regressor__alpha': 0.001, 'transformedtargetregressor__regressor__penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that performs standardization and fit the data to SGD regression model\n",
    "sr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    TransformedTargetRegressor(regressor=SGDRegressor(random_state=0), func=np.log, inverse_func=np.exp),\n",
    ")\n",
    "\n",
    "# Define a set of hyperparameters to be tested during gridsearch\n",
    "sr_model_params = {\n",
    "    \"transformedtargetregressor__regressor__alpha\": np.logspace(-3,-7, num= 5),\n",
    "    \"transformedtargetregressor__regressor__penalty\": ['l2', 'l1', 'elasticnet'],\n",
    "}\n",
    "\n",
    "# Create a gridsearch object to find the optimum hyperparameters\n",
    "sr_model_gs = GridSearchCV(\n",
    "    sr_model,\n",
    "    sr_model_params,\n",
    "    cv=5,\n",
    "    return_train_score=True,\n",
    "    verbose=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to the preprocessed train dataset\n",
    "sr_model_gs.fit(X_tr_p0, y_tr)\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset with the best hyperparameters \n",
    "sr_y_pred = sr_model_gs.predict(X_te_p0)\n",
    "\n",
    "print('The MSE of the linear regression model is: {:.1f}'.format(MSE(y_te, sr_y_pred)))\n",
    "print('The MAE of the linear regression model is: {:.1f}'.format(MAE(y_te, sr_y_pred)))\n",
    "\n",
    "print(\"\\n The best parameters across all searched params:\\n\",sr_model_gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:** All three linear model regression models show similar performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression: testing polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr: (824654, 139)\n",
      "X_te: (206156, 139)\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to the train dataset\n",
    "X_tr_p1 = preprocess(X_tr, categorical_cols, continuous_cols, [\"trip_distance\"])\n",
    "\n",
    "# Apply preprocessing to the train dataset\n",
    "X_te_p1 = preprocess(X_te, categorical_cols, continuous_cols, [\"trip_distance\"])\n",
    "\n",
    "print(\"X_tr:\", X_tr_p.shape)\n",
    "print(\"X_te:\", X_te_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the linear regression model is: 26.1\n",
      "The MAE of the linear regression model is: 2.1\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that performs standardization and fit the data to linear regression model\n",
    "lr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=LinearRegression(), func=np.log, inverse_func=np.exp\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to the preprocessed train dataset\n",
    "lr_model.fit(X_tr_p1, y_tr)\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset\n",
    "lr_y_pred = lr_model.predict(X_te_p1)\n",
    "\n",
    "print('The MSE of the linear regression model is: {:.1f}'.format(MSE(y_te, lr_y_pred)))\n",
    "print('The MAE of the linear regression model is: {:.1f}'.format(MAE(y_te, lr_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr: (824654, 157)\n",
      "X_te: (206156, 157)\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to the train dataset\n",
    "X_tr_p2 = preprocess(X_tr, categorical_cols, continuous_cols, [\"trip_distance\"], 2)\n",
    "\n",
    "# Apply preprocessing to the train dataset\n",
    "X_te_p2 = preprocess(X_te, categorical_cols, continuous_cols, [\"trip_distance\"], 2)\n",
    "\n",
    "print(\"X_tr:\", X_tr_p2.shape)\n",
    "print(\"X_te:\", X_te_p2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the linear regression model is: 25.3\n",
      "The MAE of the linear regression model is: 2.1\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that performs standardization and fit the data to linear regression model\n",
    "lr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=LinearRegression(), func=np.log, inverse_func=np.exp\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to the preprocessedtrain dataset\n",
    "lr_model.fit(X_tr_p2, y_tr)\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset\n",
    "lr_y_pred = lr_model.predict(X_te_p2)\n",
    "\n",
    "print('The MSE of the linear regression model is: {:.1f}'.format(MSE(y_te, lr_y_pred)))\n",
    "print('The MAE of the linear regression model is: {:.1f}'.format(MAE(y_te, lr_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr: (824654, 163)\n",
      "X_te: (206156, 163)\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to the train dataset\n",
    "X_tr_p3 = preprocess(X_tr, categorical_cols, continuous_cols, [\"trip_distance\"], 3)\n",
    "\n",
    "# Apply preprocessing to the train dataset\n",
    "X_te_p3 = preprocess(X_te, categorical_cols, continuous_cols, [\"trip_distance\"], 3)\n",
    "\n",
    "print(\"X_tr:\", X_tr_p3.shape)\n",
    "print(\"X_te:\", X_te_p3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the linear regression model is: 25.0\n",
      "The MAE of the linear regression model is: 2.1\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that performs standardization and fit the data to linear regression model\n",
    "lr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=LinearRegression(), func=np.log, inverse_func=np.exp\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to the preprocessed train dataset\n",
    "lr_model.fit(X_tr_p3, y_tr)\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset\n",
    "lr_y_pred = lr_model.predict(X_te_p3)\n",
    "\n",
    "print('The MSE of the linear regression model is: {:.1f}'.format(MSE(y_te, lr_y_pred)))\n",
    "print('The MAE of the linear regression model is: {:.1f}'.format(MAE(y_te, lr_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:** Polynomial features improve the performance of the linear regression model. However, no significant improvement is obtained when using polynomials of degree three and above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression: testing different feature spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr: (824654, 157)\n",
      "X_te: (206156, 157)\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to the train dataset\n",
    "X_tr_p4 = preprocess(X_tr, categorical_cols, continuous_cols, [\"trip_distance\"], 2)\n",
    "\n",
    "# Apply preprocessing to the train dataset\n",
    "X_te_p4 = preprocess(X_te, categorical_cols, continuous_cols, [\"trip_distance\"], 2)\n",
    "\n",
    "print(\"X_tr:\", X_tr_p4.shape)\n",
    "print(\"X_te:\", X_te_p4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr: (824654, 151)\n",
      "X_te: (206156, 151)\n"
     ]
    }
   ],
   "source": [
    "# Create a subset of the train matrix without holiday data\n",
    "X_tr_p4_sub1 = X_tr_p4.drop(columns=[col for col in X_tr_p4.columns if \"holiday\" in col])\n",
    "\n",
    "# Create a subset of the test matrix without holiday data\n",
    "X_te_p4_sub1 = X_te_p4.drop(columns=[col for col in X_te_p4.columns if \"holiday\" in col])\n",
    "\n",
    "print(\"X_tr:\", X_tr_p4_sub1.shape)\n",
    "print(\"X_te:\", X_te_p4_sub1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the linear regression model is: 25.4\n",
      "The MAE of the linear regression model is: 2.1\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that performs standardization and fit the data to linear regression model\n",
    "lr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=LinearRegression(), func=np.log, inverse_func=np.exp\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to the train dataset\n",
    "lr_model.fit(X_tr_p4_sub1, y_tr)\n",
    "\n",
    "# Predict the target variable of the test dataset\n",
    "lr_y_pred = lr_model.predict(X_te_p4_sub1)\n",
    "\n",
    "print('The MSE of the linear regression model is: {:.1f}'.format(MSE(y_te, lr_y_pred)))\n",
    "print('The MAE of the linear regression model is: {:.1f}'.format(MAE(y_te, lr_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr: (824654, 126)\n",
      "X_te: (206156, 126)\n"
     ]
    }
   ],
   "source": [
    "# Create a subset of the train matrix without weather forecast data\n",
    "X_tr_p4_sub2 = X_tr_p4.drop(columns=[col for col in X_tr_p4.columns if \"wf\" in col])\n",
    "\n",
    "# Create a subset of the test matrix without weather forecast data\n",
    "X_te_p4_sub2 = X_te_p4.drop(columns=[col for col in X_te_p4.columns if \"wf\" in col])\n",
    "\n",
    "print(\"X_tr:\", X_tr_p4_sub2.shape)\n",
    "print(\"X_te:\", X_te_p4_sub2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the linear regression model is: 25.4\n",
      "The MAE of the linear regression model is: 2.1\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that performs standardization and fit the data to linear regression model\n",
    "lr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=LinearRegression(), func=np.log, inverse_func=np.exp\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to the train dataset\n",
    "lr_model.fit(X_tr_p4_sub2, y_tr)\n",
    "\n",
    "# Predict the target variable of the test dataset\n",
    "lr_y_pred = lr_model.predict(X_te_p4_sub2)\n",
    "\n",
    "print('The MSE of the linear regression model is: {:.1f}'.format(MSE(y_te, lr_y_pred)))\n",
    "print('The MAE of the linear regression model is: {:.1f}'.format(MAE(y_te, lr_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr: (824654, 120)\n",
      "X_te: (206156, 120)\n"
     ]
    }
   ],
   "source": [
    "# Create a subset of the train matrix without holiday and weather forecastdata\n",
    "X_tr_p4_sub3 = X_tr_p4.drop(columns=[col for col in X_tr_p4.columns if \"wf\" in col or \"holiday\" in col])\n",
    "\n",
    "# Create a subset of the test matrix without holiday and weather forecast data\n",
    "X_te_p4_sub3 = X_te_p4.drop(columns=[col for col in X_te_p4.columns if \"wf\" in col or \"holiday\" in col])\n",
    "\n",
    "print(\"X_tr:\", X_tr_p4_sub3.shape)\n",
    "print(\"X_te:\", X_te_p4_sub3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the linear regression model is: 25.5\n",
      "The MAE of the linear regression model is: 2.1\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that performs standardization and fit the data to linear regression model\n",
    "lr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=LinearRegression(), func=np.log, inverse_func=np.exp\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to the train dataset\n",
    "lr_model.fit(X_tr_p4_sub3, y_tr)\n",
    "\n",
    "# Predict the target variable of the test dataset\n",
    "lr_y_pred = lr_model.predict(X_te_p4_sub3)\n",
    "\n",
    "print('The MSE of the linear regression model is: {:.1f}'.format(MSE(y_te, lr_y_pred)))\n",
    "print('The MAE of the linear regression model is: {:.1f}'.format(MAE(y_te, lr_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:** Reducing the feature space by removing less informative variables does not affect performance, but significantly reduces computation time. It can also results in a more accurate and interpretable model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression: testing dimensionality reduction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the linear regression model is: 34.2\n",
      "The MAE of the linear regression model is: 2.2\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that performs standardization and fit the data to linear regression model\n",
    "lr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PCA(n_components = 0.95),\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=LinearRegression(), func=np.log, inverse_func=np.exp\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to the train dataset\n",
    "lr_model.fit(X_tr_p4, y_tr)\n",
    "\n",
    "# Predict the target variable of the test dataset\n",
    "lr_y_pred = lr_model.predict(X_te_p4)\n",
    "\n",
    "print('The MSE of the linear regression model is: {:.1f}'.format(MSE(y_te, lr_y_pred)))\n",
    "print('The MAE of the linear regression model is: {:.1f}'.format(MAE(y_te, lr_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the linear regression model is: 31.0\n",
      "The MAE of the linear regression model is: 2.2\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that performs standardization and fit the data to linear regression model\n",
    "lr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PCA(n_components = 0.99),\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=LinearRegression(), func=np.log, inverse_func=np.exp\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to the train dataset\n",
    "lr_model.fit(X_tr_p4, y_tr)\n",
    "\n",
    "# Predict the target variable of the test dataset\n",
    "lr_y_pred = lr_model.predict(X_te_p4)\n",
    "\n",
    "print('The MSE of the linear regression model is: {:.1f}'.format(MSE(y_te, lr_y_pred)))\n",
    "print('The MAE of the linear regression model is: {:.1f}'.format(MAE(y_te, lr_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the linear regression model is: 35.9\n",
      "The MAE of the linear regression model is: 2.3\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that performs standardization and fit the data to linear regression model\n",
    "lr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PCA(n_components = 0.95),\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=LinearRegression(), func=np.log, inverse_func=np.exp\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to the train dataset\n",
    "lr_model.fit(X_tr_p4_sub3, y_tr)\n",
    "\n",
    "# Predict the target variable of the test dataset\n",
    "lr_y_pred = lr_model.predict(X_te_p4_sub3)\n",
    "\n",
    "print('The MSE of the linear regression model is: {:.1f}'.format(MSE(y_te, lr_y_pred)))\n",
    "print('The MAE of the linear regression model is: {:.1f}'.format(MAE(y_te, lr_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the linear regression model is: 31.9\n",
      "The MAE of the linear regression model is: 2.2\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that performs standardization and fit the data to linear regression model\n",
    "lr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PCA(n_components = 0.99),\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=LinearRegression(), func=np.log, inverse_func=np.exp\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to the train dataset\n",
    "lr_model.fit(X_tr_p4_sub3, y_tr)\n",
    "\n",
    "# Predict the target variable of the test dataset\n",
    "lr_y_pred = lr_model.predict(X_te_p4_sub3)\n",
    "\n",
    "print('The MSE of the linear regression model is: {:.1f}'.format(MSE(y_te, lr_y_pred)))\n",
    "print('The MAE of the linear regression model is: {:.1f}'.format(MAE(y_te, lr_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:** Reducing the feature space with principal component analysis (PCA) worsens the performance of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Linear Regression: final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr: (824654, 157)\n",
      "X_te: (206156, 157)\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to the train dataset\n",
    "X_tr_p5 = preprocess(X_tr, categorical_cols, continuous_cols, [\"trip_distance\"], 2)\n",
    "\n",
    "# Apply preprocessing to the train dataset\n",
    "X_te_p5 = preprocess(X_te, categorical_cols, continuous_cols, [\"trip_distance\"], 2)\n",
    "\n",
    "print(\"X_tr:\", X_tr_p5.shape)\n",
    "print(\"X_te:\", X_te_p5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr: (824654, 120)\n",
      "X_te: (206156, 120)\n"
     ]
    }
   ],
   "source": [
    "# Create a subset of the train matrix without holiday and weather forecastdata\n",
    "X_tr_p5_sub1 = X_tr_p5.drop(columns=[col for col in X_tr_p4.columns if \"wf\" in col or \"holiday\" in col])\n",
    "\n",
    "# Create a subset of the test matrix without holiday and weather forecast data\n",
    "X_te_p5_sub1 = X_te_p5.drop(columns=[col for col in X_te_p4.columns if \"wf\" in col or \"holiday\" in col])\n",
    "\n",
    "print(\"X_tr:\", X_tr_p5_sub1.shape)\n",
    "print(\"X_te:\", X_te_p5_sub1.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the linear regression model is: 25.5\n",
      "The MAE of the linear regression model is: 2.1\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that performs standardization and fit the data to Ridge regression model\n",
    "lr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=LinearRegression(),\n",
    "        func=np.log,\n",
    "        inverse_func=np.exp,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Fit and evaluate the pipeline to the preprocessed train dataset\n",
    "lr_model.fit(X_tr_p5_sub1, y_tr)\n",
    "\n",
    "# Predict the target variable of the preprocessed test dataset with the best hyperparameters\n",
    "lr_y_pred = lr_model.predict(X_te_p5_sub1)\n",
    "\n",
    "print(\"The MSE of the linear regression model is: {:.1f}\".format(MSE(y_te, lr_y_pred)))\n",
    "print(\"The MAE of the linear regression model is: {:.1f}\".format(MAE(y_te, lr_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Export Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data frame containing the MSE and MAE of the model\n",
    "sr_results = pd.DataFrame({\n",
    "    'model':['lr'],\n",
    "    'mse':[MSE(y_te, sr_y_pred)],\n",
    "    'mae':[MAE(y_te, sr_y_pred)],\n",
    "})\n",
    "\n",
    "# Save the results in the project folder\n",
    "sr_results.to_csv('results/lr_model.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPBFy6LDJ28+i+mv+3BWFx7",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "01.data",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "f0bf25c6fa4e57b7fa36a98c8f4215014c209bd59bf7f61e8cb59f3c04a18758"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "f0bf25c6fa4e57b7fa36a98c8f4215014c209bd59bf7f61e8cb59f3c04a18758"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
